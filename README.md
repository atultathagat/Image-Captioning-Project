
# Image Captioning Project
I have a developed a Deep Learning Model with the help of tensorflow and keras for generating captions on various images. To extract the features of the image I have used pretrained VGG16 model.

## Dataset
The model is trained on Flickr8k Dataset

## Performance
I have acheived a `BLEU-1 = ~0.55` with 1000 testing samples.

## Results

Image | Caption 
--- | --- 
<img src="Examples/example_1.jpg" width="300"> | **Caption generated**: black dog is running through the water
<img src="Examples/example_2.jpg" width="300"> | **Caption generated**: two men are playing soccer
<img src="Examples/example_3.jpg" width="300"> | **Caption generated**: skier is skiing down snowy hill
<img src="Examples/example_4.jpg" width="300"> | **Caption generated**: man in red shirt is riding on the beach
<img src="Examples/example_5.jpg" width="300"> | **Caption generated**: surfer is surfing wave



